<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.80.0" />


<title>Writting a linear algebra library on C&#43;&#43; - Data science and Econometrics</title>
<meta property="og:title" content="Writting a linear algebra library on C&#43;&#43; - Data science and Econometrics">


  <link href='../../../../favicons.ico' rel='icon' type='image/x-icon'/>


  








<link href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../../../../css/fonts.css" media="all">
<link rel="stylesheet" href="../../../../css/main.css" media="all">



  </head>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P6FER778X2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-P6FER778X2');
</script>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  

  <ul class="nav-links">
    
    <li><a href="../../../../">Home</a></li>
    
    <li><a href="../../../../about/">About</a></li>
    
  </ul>
</nav>

      </header>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">8 min read</span>
    

    <h1 class="article-title">Writting a linear algebra library on C&#43;&#43;</h1>

    
    <span class="article-date">2021-09-15</span>
    

    <div class="article-content">
      <!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h1 id="introduction">Introduction:</h1>
<p>SVD is one of the most important algorithms in Statistics and Machine learning.
It is used to perform dimension reduction (in PCA), to solve linear equations
etc. SVD is a matrix factorization, let X be an $n \times m$ matrix, the Sinvular value decomposition of X is : $X = U \Sigma V^{*}$ U and V are unitary matrices. Z is a diagonal matrix containing the singular values of X.</p>
<p>In this technical note, I am explaining how I used C++ to implement a basic linear algebra library which can compute numerically PCA using the SVD. First, I present the algorithms and matrix operations implemented, necessary to  perform
the SVD. After that,  I am explaining my C++ implementation, notably, the classes and funtions that I wrote to perform the computations.</p>
<h1 id="the-math-implimented">The Math implimented</h1>
<p>This library perform PCA using the SVD. Let $X$ be an $n-by-m$ <em>real</em> matrix (a dataset).</p>
<h5 id="mathematically-the-svd-of-x-is-define-as">Mathematically, the SVD of X is define as</h5>
<p>$X = U\Sigma V^{t}$</p>
<ul>
<li>$V$ correspond to the eigenvectors of $X^tX$, where $X^t$ is the transpose of $X$. $V^t$ is the matrix transpose of $V$</li>
<li>$U$ correspond to the eigenvectors of $XX^t$.</li>
<li>$\Sigma$ is a matrix containing the square root of the eigenvalues of  $XX^t$
or $X^tX$ ($eigvalues(XX^t) = eigvalues(X^tX)$).</li>
</ul>
<h5 id="to-obtain-the-principal-components--from-the-svd">To obtain the principal components  from the SVD:</h5>
<ul>
<li>Compute $\bar{X}$, the colmeans of $X$. Then compute : $M = X - \bar{X}$.</li>
<li>Compute the SVD of $M$: $M = U\Sigma V^t$.</li>
<li>Compute the <strong>PC</strong> (principal components): $PC  =  U\Sigma$.</li>
<li>The Explained Variance is obtained from the computation: $\frac{\sigma_i^2}{\sum_{i=0}^k\sigma_i^2}$, where $\sigma_i$ is a singular value.</li>
</ul>
<h5 id="computing-numerically-the-svd">Computing numerically the SVD</h5>
<p>I computed $Z$, $V$ and $U$ by the following way:</p>
<ul>
<li>
<p>I performed an eigendecomposition of $X^tX$ to obtain $V$ and $\sqrt(\Sigma)$.</p>
<blockquote>
<p>$Z, V = eigendecomposition(X^tX)$.</p>
</blockquote>
</li>
<li>
<p>$U$ is derived from this equation: $AV =  UZ$</p>
<blockquote>
<p>for each vector $u_i$ in the matrix $U$, $u_i = a_i * v_i/\sigma_i$</p>
</blockquote>
</li>
</ul>
<p>Thus, to compute the SVD, I need to implement a numerical computation of eigenvectors and eigenvalues (the eigendecomposition).</p>
<h4 id="how-to-compute-numerically-eigenvectors-and-eigenvalues"><em>How to compute numerically eigenvectors and eigenvalues?</em></h4>
<p>There are many <a href="https://en.wikipedia.org/wiki/Eigenvalue_algorithm">algorithms to compute eigenvalues and eigenvectors</a>.
One of the most used is the QR algorithm. Hence, to compute the eigen decomposition, I need to implement the QR algorithm first.</p>
<dl>
<dt>The QR algorithm</dt>
<dd>Is used to find eigenvectors and eigenvalues of a matrix. Let $A$ be a matrix, the QR algorithm consist of computing iterativelly the <strong>QR factorization</strong> of $A$. And the QR factorization of $A$ :
$A = QR$, $Q$ is a orthogonal matrix and $R$ is a triangular matrix.</dd>
</dl>
<p>The basic QR algorithm can be described by the following way:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">set E <span style="color:#f92672">=</span> A
set V <span style="color:#f92672">=</span> I 		<span style="color:#75715e"># I is the identity matrix </span>
<span style="color:#66d9ef">for</span> k <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>, <span style="color:#f92672">...</span> (until convergence)
 	E <span style="color:#f92672">=</span> QR		<span style="color:#75715e"># QR factorization</span>
	E <span style="color:#f92672">=</span> RQ		<span style="color:#75715e"># The next A</span>
	V <span style="color:#f92672">=</span> V <span style="color:#f92672">*</span> Q 
</code></pre></div><p>At convergenace, $E$ becomes a triangular matrix and its diagonal elements are the eigenvalues of $A$. The matrix $V$ contains the eigenvectors of $A$.</p>
<blockquote>
<p>Note: eigenvalues are unique, but eigenvectors are not.</p>
</blockquote>
<p>To implement the QR algorithm, I need to implement first the <strong>QR factorization</strong> ( also called QR decomposition), which consist of computing $Q \text{ and } R$.</p>
<h4 id="computing-q-and-r-numerically"><em>Computing Q and R numerically</em></h4>
<p>There exist many methods to compute the orthogonal matrix $Q$ such as Gram-Schmidt, householder reflections, givens rotations.  I choose to implement the Householder transformation.</p>
<dl>
<dt>Householder</dt>
<dd>The householder reflection of a vector $x \in A_{n \times m}$ is the matrix $P$, given by :
<p>$P = I - 2\frac{vv^t}{v^tv}$,</p>
<p>Where:</p>
</dd>
</dl>
<ul>
<li>$I$ is an $m-by-m$ identity matrix,</li>
<li>$v = x + sign(x[0]) \times norm(x) \times e$ and $x$ and $e$ are columns vectors, of same length $m$. And $e = (1,0,0,&hellip;).$</li>
</ul>
<p>To Compute the householder transformation, I need to implement all necessary matrix operations, matrix subscripting from scratch.</p>
<h4 id="what-matrix-operations-are-needed"><em>What matrix operations are needed?</em></h4>
<ul>
<li>Arithmetic operations : Addition, multiplication, soustraction by another matrix and by a scaler. Plus division of matrix by a scaler.</li>
<li>Matrix transformations : Transpose, diagonalization, norm of a vector</li>
<li>Special matrices: Identity matrix, diagonal matrix, matrix of zeros,</li>
<li>Statistics : mean, average of a matrix by column, by row, sum, etc.</li>
</ul>
<p>The implemented code written in C++ is explained below.</p>
<h1 id="the-c-implementation-code">The C++ implementation code</h1>
<blockquote>
<p>The repo : <a href="https://github.com/sowb/lib-linear-alg">https://github.com/sowb/lib-linear-alg</a></p>
</blockquote>
<p>I implemented a class named <em>Matrix</em> to represent a matrix.
The file <strong>matrix.h</strong> contains the implementation.</p>
<h3 id="private-members">Private members</h3>
<p><code>nb_row</code> and <code>nb_col</code> store the number of rows and the number of columns of the matrix.</p>
<p><code>mat_data</code> is a <code>std::vector&lt;double&gt;</code>, it stores the  matrix data, the ij values.</p>
<h3 id="constructors">Constructors</h3>
<p>The class has 5 constructors. A constructor to generate random matrices (uniformely or normaly), a constructor to <em>load data from a CSV file</em> and create a matrix, a constructor to create a matrix using an initializer list or a vector of vectors.</p>
<h3 id="overloaded-operators">Overloaded operators</h3>
<p><em>Arithmetic operators</em> : implement arithmetic operations between a matrix and a matrix, between matrix and a scaler.</p>
<!-- raw HTML omitted -->
<p>Multiplication  <code>*</code>, <code>*=</code></p>
<p>Addition  <code>+</code>, <code>+=</code></p>
<p>Substraction  <code>-</code>, <code>-=</code></p>
<p>Division  <code>\</code></p>
<p>Equal  <code>==</code></p>
<p>Difference  <code>!=</code></p>
<!-- raw HTML omitted -->
<p><em>The subscript operators</em> : <code>()</code> and <code>[]</code>, for accessing and modifying a matrix values, or slicing a matrix.</p>
<h3 id="member-functions">Member functions</h3>
<!-- raw HTML omitted -->
<p><code>column</code> and <code>row</code>  to get a column or a row of a matrix.</p>
<p><code>sub_matrix</code>  return a submatrix of a matrix.</p>
<p><code>shape</code>  print the dimension of a matrix.</p>
<p><code>reshape</code> reshape (change the number of rows and columns) of a matrix.</p>
<p><code>add_row</code> and <code>add_column</code>  add a new column or a new row to a matrix.</p>
<p><code>remove_column</code> delete a column of a matrix.</p>
<p><code>reorder_column</code> sort a matrix column, or flat matrix.</p>
<p><code>sort_matrix</code> sort a matrix by column, using indexes</p>
<p><code>T()</code> and <code>transpose</code> (a friend function): return the transpose of the matrix.</p>
<p><code>Id</code> create a unitary matrix.</p>
<p><code>sum</code>  return the sum a flattened matrix.</p>
<p><code>avg</code>  compute the average of a flattened matrix.</p>
<p><code>head</code> print first row of matrix</p>
<p><code>print</code> formated print of a matrix, a value, a string.</p>
<p><code>to_csv</code> save a matrix in  a csv file.</p>
<!-- raw HTML omitted -->
<h3 id="non-member-functions">Non member functions</h3>
<!-- raw HTML omitted -->
<p><code>print</code> formated print of a matrix, a value, a string.</p>
<p><code>as_matrix</code>  convert a <code>std::vector</code> type to a Matrix type.</p>
<p><code>as_vector</code>  convert a Matrix type to <code>std::vector</code>.</p>
<p><code>sgn</code> return the sign of a scalar</p>
<p><code>norm</code> compute the norm of a vector</p>
<p><code>elm2pow_n</code> compute the power n of a matrix.</p>
<p><code>mean</code> and <code>stdev</code> compute the mean and standard deviation of a matrix.</p>
<p><code>tile</code> repeat n times a row or column of a matrix.</p>
<p><code>scale</code> scale a matrix $(x - \bar{x})/\sigma)$</p>
<p><code>uniform_dist</code> and <code>normal_dist</code> generate a random number from a uniform dist or normal distribution</p>
<p><code>diag_matrix</code> return a diagonal matrix.</p>
<p><code>householder</code> compute the householder reflector</p>
<p><code>QR_factorization</code> Matrix factorization using QR-factorization</p>
<p><code>is_triangular</code> Check if a matrix is triangular</p>
<p><code>hessenberg</code> transform a matrix to upper hessemberg</p>
<p><code>wilkinson_shift</code> compute the wilkinson shift</p>
<p><code>QR_algorithm_w_shift</code> compute the QR algorithm with shift of a matrix.</p>
<p><code>eigen_decomposition</code> eigen decompostion  of a matrix using the basic QR algorithm</p>
<p><code>SVD</code> Compute the singular value decomposition of a matrix using the QR algorithm.</p>
<p><code>PCA</code> Compute the Principale Components Analysis of a matrix using SVD.</p>
<p><code>save2csv</code> save a matrix to csv.</p>
<!-- raw HTML omitted -->
<h3 id="futur-improvements">Futur improvements</h3>
<blockquote>
<p>The QR algorithm and the SVD implemented in this library are basic implementations. More sophisticated  and efficient algorithms exist (see).</p>
</blockquote>
<p>The implementation can be improved in mathematical level and the computation level, by :</p>
<ul>
<li>using parallelization and multi-threading of the code</li>
<li>calling LAPACK and BLAS routines from C++. This is what is done by the library Eigen (in C++) and Numpy (in Python).</li>
</ul>
<h2 id="how-to-use-the-library---simple-example">How to use the library - Simple example</h2>
<ul>
<li>Download the code</li>
<li>On the terminal run the file <code>usage-examples.cpp</code>.</li>
</ul>
<p><strong>Compile on Linx</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">cd lib-linear-alg/examples/
g++ -std<span style="color:#f92672">=</span>c++11 usage-examples.cpp ../lib-unix/libLinearAlg.a <span style="color:#f92672">&amp;&amp;</span> ./a.out
</code></pre></div><p><strong>Compile on Windows</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">cd lib-linear-alg/examples/
g++ -std<span style="color:#f92672">=</span>c++11 usage-examples.cpp ../lib-windows/libLinearAlg.lib <span style="color:#f92672">&amp;&amp;</span> ./a.exe
</code></pre></div><ul>
<li>The content of the file <code>usage-examples.cpp</code></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e">#include &lt;iostream&gt;</span>
<span style="color:#75715e">#include &#34;../include/matrix.h&#34;</span>
using namespace std;

int main<span style="color:#f92672">()</span>
<span style="color:#f92672">{</span>
    // Generate 5x4 random matrix
    Matrix A<span style="color:#f92672">(</span>5, 4, unif<span style="color:#f92672">(</span>-1, 1<span style="color:#f92672">))</span>; //rnorm - <span style="color:#66d9ef">for</span> the normal distribution
    A.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;matrix A:&#34;</span><span style="color:#f92672">)</span>;
    transpose<span style="color:#f92672">(</span>A<span style="color:#f92672">)</span>.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Transpose A:&#34;</span><span style="color:#f92672">)</span>;
    // Create matrix 4x4 matrix ;
    Matrix B <span style="color:#f92672">=</span> <span style="color:#f92672">{{</span>2, 0, 8, 10, 7<span style="color:#f92672">}</span>,
                <span style="color:#f92672">{</span>3, 41, 9, 4, 1<span style="color:#f92672">}</span>,
                <span style="color:#f92672">{</span>1, 5, 5, 86, 4<span style="color:#f92672">}}</span>;

    B.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;matrix B:&#34;</span><span style="color:#f92672">)</span>;

    // Transpose matrix
    Matrix C <span style="color:#f92672">=</span> B.T<span style="color:#f92672">()</span> * B;
    C.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;B.T * B:&#34;</span><span style="color:#f92672">)</span>;

    //Get the Diagonal of the matrix
    Matrix D <span style="color:#f92672">=</span> diag<span style="color:#f92672">(</span>B<span style="color:#f92672">)</span>;
    D.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Diagonal of D:&#34;</span><span style="color:#f92672">)</span>;

    // Create a diagonal matrix
    Matrix Dmat <span style="color:#f92672">=</span> diag_matrix<span style="color:#f92672">(</span>D<span style="color:#f92672">)</span>;
    Dmat.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\nDiagonal Matrix:&#34;</span><span style="color:#f92672">)</span>;

    //QR factorization
    Matrix E <span style="color:#f92672">=</span> <span style="color:#f92672">{{</span>12, -51, 4<span style="color:#f92672">}</span>, <span style="color:#f92672">{</span>6, 167, -68<span style="color:#f92672">}</span>, <span style="color:#f92672">{</span>-4, 24, -41<span style="color:#f92672">}}</span>;
    E.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;E:&#34;</span><span style="color:#f92672">)</span>;
    print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\nQR factorization of E:\n&#34;</span><span style="color:#f92672">)</span>;
    Matrix Q, R;
    QR_factorization<span style="color:#f92672">(</span>E, &amp;Q, &amp;R<span style="color:#f92672">)</span>;
    Q.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Q:&#34;</span><span style="color:#f92672">)</span>;
    R.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;R:&#34;</span><span style="color:#f92672">)</span>;
    <span style="color:#f92672">(</span>Q * R<span style="color:#f92672">)</span>.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Check QR = B&#34;</span><span style="color:#f92672">)</span>;

    // eigen decomposition
    print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\nEigen decomposition of E&#34;</span><span style="color:#f92672">)</span>;
    Matrix EigVal, EigVec;
    eigen_decomposition<span style="color:#f92672">(</span>E, &amp;EigVal, &amp;EigVec<span style="color:#f92672">)</span>; // use the basic QR
    EigVal.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;EigVal:&#34;</span><span style="color:#f92672">)</span>;
    EigVec.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;EigVec&#34;</span><span style="color:#f92672">)</span>;

    // Eigen decomposition using QR with shift
    QR_algorithm_w_shift<span style="color:#f92672">(</span>E, &amp;EigVal, &amp;EigVec<span style="color:#f92672">)</span>;
    EigVal.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;EigVal-QR shift:&#34;</span><span style="color:#f92672">)</span>;
    EigVec.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;EigVec-QR shift&#34;</span><span style="color:#f92672">)</span>;

    //Scaling a matrix : <span style="color:#f92672">(</span>x-x_bar<span style="color:#f92672">)</span>/std<span style="color:#f92672">(</span>x<span style="color:#f92672">)</span>
    Matrix F <span style="color:#f92672">=</span> scale<span style="color:#f92672">(</span>B, <span style="color:#e6db74">&#34;col&#34;</span><span style="color:#f92672">)</span>;
    F.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;B scaled:&#34;</span><span style="color:#f92672">)</span>;

    // Singular Value Decomposition
    print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\nSingular Value Decomposition&#34;</span><span style="color:#f92672">)</span>;
    Matrix U, S, V;
    SVD<span style="color:#f92672">(</span>F, &amp;U, &amp;S, &amp;V<span style="color:#f92672">)</span>;
    U.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;U:&#34;</span><span style="color:#f92672">)</span>;
    S.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;S:&#34;</span><span style="color:#f92672">)</span>;
    V.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;V:&#34;</span><span style="color:#f92672">)</span>;

    //Principal Component Analysis
    print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\nPrincipal Components Analysis&#34;</span><span style="color:#f92672">)</span>;
    Matrix Comp, Z, Var;

    //scale B
    PCA<span style="color:#f92672">(</span>F, &amp;Comp, &amp;Z, &amp;Var, 2<span style="color:#f92672">)</span>;
    Z.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Singular Values :&#34;</span><span style="color:#f92672">)</span>;
    Var.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Explained Variance :&#34;</span><span style="color:#f92672">)</span>;
    Comp.print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Components&#34;</span><span style="color:#f92672">)</span>;

    // Save the components in a file
    //Comp.to_csv<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;components&#34;</span><span style="color:#f92672">)</span>;

    <span style="color:#66d9ef">return</span> 0;
<span style="color:#f92672">}</span>

</code></pre></div><h4 id="computing-pca-using-the-library-">Computing PCA using the library :</h4>
<p>see ls</p>
<h1 id="references">References</h1>
<ul>
<li><strong>Numerical Linear Algebra</strong>,LLOYD N. TREFETHEN &amp; DAVID BAU III, <em>siam</em>, 1997.</li>
<li>__Fundamentals of Matrix Computations__3rd, DAVID S. WATKINS, <em>WILEY</em>, 2010</li>
</ul>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="../../../../index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="../../../../images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css/highlight.js/9.12.0/highlight.min.js"></script>



<script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css/highlight.js/9.12.0/languages/c&#43;&#43;.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css/highlight.js/9.12.0/languages/python.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../../../../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'G-P6FER778X2', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

